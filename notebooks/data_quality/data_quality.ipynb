{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91cc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364df701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duck_db_helper\n",
    "from duck_db_helper import get_table_df\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cabaa11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 500)\n",
    "conn = duckdb.connect('../data/analytical_sandboxes/analytical_sandbox_zone.db')\n",
    "match_df = get_table_df(\"matches\",conn)\n",
    "player_df = get_table_df(\"players\",conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914fc9cc",
   "metadata": {},
   "source": [
    "# Data Quality\n",
    "\n",
    "For our data quality process, we have chosen to utilize the outputs from the analytical sandboxes. This decision is based on the fact that the data in these sandboxes is in its raw form, without any encoding or feature generation. By evaluating the data quality at this stage, we can ensure its integrity before proceeding to further data manipulations. If the data exhibits poor quality at this initial stage, it is likely to maintain the same level of quality in subsequent steps.\n",
    "\n",
    "## 1. Understanding and Identifying Data Quality Issues\n",
    "\n",
    "### 1.1. Data Profiling\n",
    "\n",
    "First we are going to list all the shortenings and its real meaning.\n",
    "\n",
    "#### Matches\n",
    "\n",
    "1. Match data\n",
    "    * **Date**: The date on which the match was played.\n",
    "    * **HomeTeam**: Team that plays the match on its own field.\n",
    "    * **AwayTeam**: Foreign team.\n",
    "    * **FTHG**: HomeTeam goals.\n",
    "    * **FTAG**: AwayTeam goals.\n",
    "    * **FTR**: Result of the match, H means HomeTeam won, D means Draw and A means AwayTeam won. \n",
    "2. Betting Statistics\n",
    "    * **AvgH**: Average of the betting for HomeTeam winning.\n",
    "    * **AvgD**: Average of the betting for draw.\n",
    "    * **AvgA**: Average of the betting for AwayTeam winning.\n",
    "3. Weather\n",
    "    * **PRESS**: Atmosferic preassure, in hectopascals.\n",
    "    * **WDIR**: Wind direction, the letter means the cardinality of the wind.\n",
    "    * **WSPD**: Wind speed in miles per hour.\n",
    "    * **CLOUD**: Cloud coverage in scale from 0 to 8.\n",
    "    * **TEMP**: Temperature in Celcius.\n",
    "    * **TDEW**: Dew point temperature in Celcius.\n",
    "    \n",
    "#### Players\n",
    "\n",
    "1. Match specific information:\n",
    "    * **match_date**: The date on which the match was played.\n",
    "    * **team_x**: The team being analyzed in the fantasy context.\n",
    "    * **opp_team_name**: The opposing team's name.\n",
    "    * **was_home**: Indicates whether the team_x played at their home ground (1) or is from the opponent team (0).\n",
    "2. Basic player information\n",
    "    * **name**: The name of the player.\n",
    "    * **position**: The playing position of the player (e.g., forward, midfielder, defender, goalkeeper).\n",
    "3. Statistics\n",
    "    * **assists**: Number of assists made by the player.\n",
    "    * **bonus**: Bonus points earned by the player based on performance.\n",
    "    * **bps**: Bonus Points System - a tally used to award additional points based on player performance.\n",
    "    * **clean_sheets**: Indicates whether the player's team did not concede any goals while the player was on the field (applicable to defenders and goalkeepers).\n",
    "    * **creativity**: A metric that reflects the player's ability to create goal-scoring opportunities.\n",
    "    * **element**: An identifier for the player in the fantasy game.\n",
    "    * **goals_conceded**: Number of goals conceded while the player was on the field (usually relevant for defenders and goalkeepers).\n",
    "    * **goals_scored**: Number of goals scored by the player.\n",
    "    * **ict_index**: Index combining Influence, Creativity, and Threat metrics to gauge a player's overall performance.\n",
    "    * **influence**: A measure of a player's influence on the game.\n",
    "    * **minutes**: Minutes played by the player in the match.\n",
    "    * **own_goals**: Number of own goals scored by the player.\n",
    "    * **penalties_missed**: Number of penalties missed by the player.\n",
    "    * **penalties_saved**: Number of penalties saved by the player (relevant for goalkeepers).\n",
    "    * **yellow_cards**: Number of yellow cards received by the player.\n",
    "    * **red_cards**: Number of red cards received by the player.\n",
    "    * **round**: The matchday or round of the fantasy league.\n",
    "    * **saves**: Number of saves made by the player (relevant for goalkeepers).\n",
    "    * **selected**: Indicates how often the player is chosen in fantasy teams.\n",
    "    * **threat**: A metric indicating the player's potential for scoring.\n",
    "    * **total_points**: Total fantasy points accumulated by the player.\n",
    "    * **value**: The value of the player in the fantasy league, typically related to their performance and popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14427f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.drop(['match_date','was_home'],axis=1).hist(bins=15, figsize=(15, 10))\n",
    "plt.suptitle(\"Player Statistics Data Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea3cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.drop(['Date'],axis=1).hist(bins=15, figsize=(15, 10))\n",
    "plt.suptitle(\"Match Information Data Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2948eb2",
   "metadata": {},
   "source": [
    "Upon initial manual inspection and profiling of the data, no anomalies were observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe60ee6",
   "metadata": {},
   "source": [
    "### 1.2. Data Quality Dimensions\n",
    "#### 1.2.1. Completeness\n",
    "\n",
    "In ensuring completeness, we carefully verify that every necessary detail is present in both player performance and match information datasets. This includes checking for missing values in key fields such as 'goals_scored' and 'match results', ensuring our data is comprehensive and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f07eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values in Player Performance Dataset:\")\n",
    "print(player_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Match Information Dataset:\")\n",
    "print(match_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7098c",
   "metadata": {},
   "source": [
    "#### 1.2.2. Uniqueness\n",
    "\n",
    "To maintain uniqueness, we scrutinize our datasets for duplicate entries. In the player performance dataset, we ensure each player's data is recorded only once per match. Similarly, in the match information dataset, we confirm that each match is uniquely represented, preventing data redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3e679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDuplicate Rows in Player Performance Dataset:\")\n",
    "print(player_df[player_df.duplicated()])\n",
    "\n",
    "print(\"\\nDuplicate Rows in Match Information Dataset:\")\n",
    "print(match_df[match_df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee2231",
   "metadata": {},
   "source": [
    "#### 1.2.3. Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b791e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values in 'position' column in Player Dataset:\")\n",
    "print(player_df['position'].unique())\n",
    "\n",
    "print(\"\\nUnique values in 'team_x' column in Player Dataset:\")\n",
    "print(player_df['team_x'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80ede6",
   "metadata": {},
   "source": [
    "## 2. Denial Constraints\n",
    "\n",
    "We first create a class to handle the cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc88d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenialConstraintsChecker:\n",
    "    def __init__(self, denial_constraints, df, key_columns):\n",
    "        self.dc_list = denial_constraints\n",
    "        self.df = df\n",
    "        self.key_columns = key_columns\n",
    "\n",
    "    def check_denial_constraint(self, dc):\n",
    "        invalid_rows, relevant_columns = dc(self.df)\n",
    "        if invalid_rows:\n",
    "            self.correct_rows(invalid_rows, relevant_columns)\n",
    "\n",
    "    def check_denial_constraints(self):\n",
    "        for dc in self.dc_list:\n",
    "            self.check_denial_constraint(dc)\n",
    "        print(f'FINISH: All denial constraints checked.')\n",
    "\n",
    "    def correct_rows(self, invalid_rows, relevant_columns):\n",
    "        for index in invalid_rows:\n",
    "            key_values = \", \".join([f\"{key}: {self.df.at[index, key]}\" for key in self.key_columns])\n",
    "            for col in relevant_columns:\n",
    "                current_value = self.df.at[index, col]\n",
    "                user_input = input(f\"Input new value for {col} ({key_values}) (Current: {current_value}, Enter for no change): \")\n",
    "                if user_input:\n",
    "                    self.df.at[index, col] = user_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5804fb",
   "metadata": {},
   "source": [
    "### 2.1. Denial Constraints for Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9398761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_matches(match_df):\n",
    "    duplicates = match_df.duplicated(subset=['Date', 'HomeTeam', 'AwayTeam'])\n",
    "    if duplicates.any():\n",
    "        print(\"DC1 Violation: Duplicate match entries found.\")\n",
    "        return match_df[duplicates].index.tolist(), ['Date', 'HomeTeam', 'AwayTeam']\n",
    "    return [], []\n",
    "\n",
    "def check_non_negative_goals(match_df):\n",
    "    negative_goals = match_df[(match_df['FTHG'] < 0) | (match_df['FTAG'] < 0)]\n",
    "    if not negative_goals.empty:\n",
    "        print(\"DC2 Violation: Negative goal values found.\")\n",
    "        return negative_goals.index.tolist(), ['FTHG', 'FTAG']\n",
    "    return [], []\n",
    "\n",
    "def check_match_result_logic(match_df):\n",
    "    result_logic = (\n",
    "        (match_df['FTHG'] > match_df['FTAG']) & (match_df['FTR'] != 'H') |\n",
    "        (match_df['FTHG'] < match_df['FTAG']) & (match_df['FTR'] != 'A') |\n",
    "        (match_df['FTHG'] == match_df['FTAG']) & (match_df['FTR'] != 'D')\n",
    "    )\n",
    "    if result_logic.any():\n",
    "        print(\"DC3, DC4, DC5 Violation: Inconsistent match results found.\")\n",
    "        return match_df[result_logic].index.tolist(), ['FTHG', 'FTAG', 'FTR']\n",
    "    return [], []\n",
    "\n",
    "def check_betting_odds_validity(match_df):\n",
    "    invalid_odds = match_df[(match_df['AvgH'] <= 0) | (match_df['AvgD'] <= 0) | (match_df['AvgA'] <= 0)]\n",
    "    if not invalid_odds.empty:\n",
    "        print(\"DC6 Violation: Invalid betting odds found.\")\n",
    "        return invalid_odds.index.tolist(), ['AvgH', 'AvgD', 'AvgA']\n",
    "    return [], []\n",
    "\n",
    "def check_weather_data_integrity(match_df):\n",
    "    weather_issues = match_df[\n",
    "        (match_df['PRESS'] < 800) | (match_df['PRESS'] > 1080) |\n",
    "        (match_df['TEMP'] < -50) | (match_df['TEMP'] > 60)\n",
    "    ]\n",
    "    if not weather_issues.empty:\n",
    "        print(\"DC7, DC8 Violation: Weather data out of expected range found.\")\n",
    "        return weather_issues.index.tolist(), ['PRESS', 'TEMP']\n",
    "    return [], []\n",
    "\n",
    "def check_wind_direction_consistency(match_df):\n",
    "    valid_directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'NNE', 'ENE', 'ESE', 'SSE', 'SSW', 'WSW', 'WNW', 'NNW']\n",
    "    invalid_wdir = match_df[~match_df['WDIR'].isin(valid_directions)]\n",
    "    if not invalid_wdir.empty:\n",
    "        print(\"DC9 Violation: Invalid wind directions found.\")\n",
    "        print(invalid_wdir[['HomeTeam','AwayTeam', 'Date','WDIR']])\n",
    "        return invalid_wdir.index.tolist(), ['WDIR']\n",
    "    return [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d053e6",
   "metadata": {},
   "source": [
    "### 2.2. Denial Constraits for Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "853b6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_position_consistency(player_df):\n",
    "    inconsistent_positions = player_df.groupby('name')['position'].unique()\n",
    "    inconsistent_names = inconsistent_positions[inconsistent_positions.apply(len) > 1].index\n",
    "    if inconsistent_names.empty:\n",
    "        return [], []\n",
    "    print(\"DC1 Violation: Players with inconsistency in positions:\")\n",
    "    print(player_df[player_df['name'].isin(inconsistent_names)][['name', 'position']])\n",
    "    return player_df[player_df['name'].isin(inconsistent_names)].index.tolist(), ['position']\n",
    "\n",
    "def check_max_points(player_df, max_points=20):\n",
    "    over_point_players = player_df[player_df['total_points'] > max_points]\n",
    "    if over_point_players.empty:\n",
    "        return [], []\n",
    "    print(\"DC2 Violation: Players with unrealistically high total points found\")\n",
    "    print(over_point_players[['name', 'match_date', 'total_points']])\n",
    "    return over_point_players.index.tolist(), ['total_points']\n",
    "\n",
    "def check_double_red_card(player_df):\n",
    "    illegal_players = player_df[player_df['red_cards'] > 1]\n",
    "    if illegal_players.empty:\n",
    "        return [], []\n",
    "    print(\"DC3 Violation: Players with illegal red cards found\")\n",
    "    print(illegal_players[['name', 'match_date']])\n",
    "    return illegal_players.index.tolist(), ['red_cards']\n",
    "\n",
    "def check_goalkeepers_goals(player_df):\n",
    "    gk_goal = player_df[(player_df['position'] == 'GK') & (player_df['goals_scored'] > 0)]\n",
    "    if gk_goal.empty:\n",
    "        return [], []\n",
    "    print(\"DC4 Violation: Goalkeepers with goals found\")\n",
    "    print(gk_goal[['name', 'match_date', 'goals_scored']])\n",
    "    return gk_goal.index.tolist(), ['goals_scored']\n",
    "\n",
    "def check_unique_player_identification(player_df):\n",
    "    duplicate_players = player_df[player_df.duplicated(['name', 'match_date', 'team_x'], keep=False)]\n",
    "    if duplicate_players.empty:\n",
    "        return [], []\n",
    "    print(\"DC5 Violation: Duplicate player records in a single match from the same team found\")\n",
    "    print(duplicate_players[['name', 'match_date', 'team_x']])\n",
    "    return duplicate_players.index.tolist(), ['name', 'match_date', 'team_x']\n",
    "\n",
    "def check_player_play_time(player_df):\n",
    "    overplayed_players = player_df[player_df['minutes'] > 90]\n",
    "    if overplayed_players.empty:\n",
    "        return [], []\n",
    "    print(\"DC6 Violation: Players who played more than 90 minutes:\")\n",
    "    print(overplayed_players[['name', 'match_date', 'minutes']])\n",
    "    return overplayed_players.index.tolist(), ['minutes']\n",
    "\n",
    "def check_player_metrics(player_df):\n",
    "    invalid_metrics = player_df[(player_df['creativity'] < 0) | (player_df['threat'] < 0) | (player_df['influence'] < 0)]\n",
    "    if invalid_metrics.empty:\n",
    "        return [], []\n",
    "    print(\"DC7 Violation: Negative values in creativity, threat, or influence metrics.\")\n",
    "    print(invalid_metrics[['name', 'match_date']])\n",
    "    return invalid_metrics.index.tolist(), ['creativity', 'threat', 'influence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22120582",
   "metadata": {},
   "source": [
    "### 2.3. Denial Constraints for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "368c33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_player_goals_vs_team_goals(joined_df):\n",
    "    joined_df['team_goals'] = joined_df.apply(lambda x: x['FTHG'] if x['was_home'] == 1 else x['FTAG'], axis=1)\n",
    "    violations = joined_df[joined_df['goals_scored'] > joined_df['team_goals']].index.tolist()\n",
    "    if violations:\n",
    "        print(\"DC1 Violation: Players scoring more goals than their team in a match.\")\n",
    "    return violations, ['goals_scored']\n",
    "\n",
    "def check_player_home_status_consistency(joined_df):\n",
    "    violations = joined_df[(joined_df['was_home'] == 1) & (joined_df['team_x'] != joined_df['HomeTeam'])].index.tolist()\n",
    "    if violations:\n",
    "        print(\"DC2 Violation: Inconsistency in 'was_home' status.\")\n",
    "    return violations, ['was_home','team_x', 'HomeTeam']\n",
    "\n",
    "def check_player_team_consistency(joined_df):\n",
    "    violations = joined_df[(joined_df['team_x'] != joined_df['HomeTeam']) & (joined_df['team_x'] != joined_df['AwayTeam'])].index.tolist()\n",
    "    if violations:\n",
    "        print(\"DC3 Violation: Inconsistency in team names for players.\")\n",
    "    return violations, ['team_x','HomeTeam','AwayTeam']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c53a263",
   "metadata": {},
   "source": [
    "### 2.4 Denial Constraints checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a63f0fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input new value for WDIR (HomeTeam: Newcastle, AwayTeam: Crystal Palace, Date: 2022-03-09 00:00:00) (Current: nan, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Fulham, AwayTeam: Chelsea, Date: 2023-12-01 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: West Ham, AwayTeam: Chelsea, Date: 2023-11-02 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Arsenal, AwayTeam: Brentford, Date: 2023-11-02 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Crystal Palace, AwayTeam: Brighton, Date: 2023-11-02 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Fulham, AwayTeam: Nott'm Forest, Date: 2023-11-02 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Leicester, AwayTeam: Spurs, Date: 2023-11-02 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Southampton, AwayTeam: Wolves, Date: 2023-11-02 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Bournemouth, AwayTeam: Newcastle, Date: 2023-11-02 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Leeds, AwayTeam: Man Utd, Date: 2023-12-02 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Man City, AwayTeam: Aston Villa, Date: 2023-12-02 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Bournemouth, AwayTeam: Liverpool, Date: 2023-11-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Everton, AwayTeam: Brentford, Date: 2023-11-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Leeds, AwayTeam: Brighton, Date: 2023-11-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Leicester, AwayTeam: Chelsea, Date: 2023-11-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Spurs, AwayTeam: Nott'm Forest, Date: 2023-11-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Crystal Palace, AwayTeam: Man City, Date: 2023-11-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Fulham, AwayTeam: Arsenal, Date: 2023-12-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Man Utd, AwayTeam: Southampton, Date: 2023-12-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: West Ham, AwayTeam: Aston Villa, Date: 2023-12-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Newcastle, AwayTeam: Wolves, Date: 2023-12-03 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Leeds, AwayTeam: Crystal Palace, Date: 2023-09-04 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for WDIR (HomeTeam: Liverpool, AwayTeam: Arsenal, Date: 2023-09-04 00:00:00) (Current: None, Enter for no change): \n",
      "Input new value for total_points (name: Roberto Firmino, match_date: 2022-08-27 00:00:00) (Current: 22, Enter for no change): \n"
     ]
    }
   ],
   "source": [
    "player_df['goals_scored'] = pd.to_numeric(player_df['goals_scored'], errors='coerce')\n",
    "player_df['assists'] = pd.to_numeric(player_df['assists'], errors='coerce')\n",
    "player_df['red_cards'] = pd.to_numeric(player_df['red_cards'], errors='coerce')\n",
    "player_df['total_points'] = pd.to_numeric(player_df['total_points'], errors='coerce')\n",
    "player_df['minutes'] = pd.to_numeric(player_df['minutes'], errors='coerce')\n",
    "player_df['creativity'] = pd.to_numeric(player_df['creativity'], errors='coerce')\n",
    "player_df['threat'] = pd.to_numeric(player_df['threat'], errors='coerce')\n",
    "player_df['influence'] = pd.to_numeric(player_df['influence'], errors='coerce')\n",
    "\n",
    "\n",
    "matches_denial_constraints = [ \n",
    "    check_unique_matches,\n",
    "    check_non_negative_goals,\n",
    "    check_match_result_logic,\n",
    "    check_betting_odds_validity,\n",
    "    check_weather_data_integrity,\n",
    "    check_wind_direction_consistency\n",
    "]\n",
    "\n",
    "players_denial_constraints = [\n",
    "    check_position_consistency,\n",
    "    check_max_points,\n",
    "    check_double_red_card,\n",
    "    check_goalkeepers_goals,\n",
    "    check_unique_player_identification,\n",
    "    check_player_play_time,\n",
    "    check_player_metrics\n",
    "]\n",
    "\n",
    "joined_denial_constraints = [\n",
    "    check_player_goals_vs_team_goals,\n",
    "    check_player_home_status_consistency,\n",
    "    check_player_team_consistency\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# MATCHES DF\n",
    "\n",
    "match_dc = DenialConstraintsChecker(matches_denial_constraints,match_df,['HomeTeam','AwayTeam', 'Date'])\n",
    "match_dc.check_denial_constraints()\n",
    "\n",
    "# PLAYER DF\n",
    "\n",
    "player_dc = DenialConstraintsChecker(players_denial_constraints,player_df,['name','match_date'])\n",
    "player_dc.check_denial_constraints()\n",
    "\n",
    "# BOTH DF\n",
    "\n",
    "df_home = pd.merge(player_df, match_df, left_on=['team_x', 'match_date'], right_on=['HomeTeam', 'Date'], how='inner')\n",
    "df_away = pd.merge(player_df, match_df, left_on=['team_x', 'match_date'], right_on=['AwayTeam', 'Date'], how='inner')\n",
    "joined_df = pd.concat([df_home, df_away], ignore_index=True)\n",
    "\n",
    "joined_dc = DenialConstraintsChecker(joined_denial_constraints,joined_df,['name','match_date'])\n",
    "joined_dc.check_denial_constraints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "680fec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undo the join\n",
    "player_columns = [col for col in joined_df.columns if col in player_df.columns]\n",
    "match_columns = [col for col in joined_df.columns if col in match_df.columns]\n",
    "\n",
    "player_changes_df = joined_df[player_columns].drop_duplicates()\n",
    "match_changes_df = joined_df[match_columns].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c88823a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytical_sandbox_db = '../data/analytical_sandboxes/analytical_sandbox_zone.db'\n",
    "\n",
    "conn = duckdb.connect(analytical_sandbox_db)\n",
    "duck_db_helper.create_table('matches', match_changes_df, conn)\n",
    "duck_db_helper.create_table('players', player_changes_df, conn)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonlocal",
   "language": "python",
   "name": "pythonlocal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
