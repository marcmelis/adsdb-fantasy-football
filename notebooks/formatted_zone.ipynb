{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e333ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import camelot\n",
    "import PyPDF2\n",
    "import glob\n",
    "import re\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from dtype_dictionaries import create_dtype_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b34a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_month(match):\n",
    "    month_abbreviations = {\n",
    "        \"January\": \"01\",\n",
    "        \"February\": \"02\",\n",
    "        \"March\": \"03\",\n",
    "        \"April\": \"04\",\n",
    "        \"May\": \"05\",\n",
    "        \"June\": \"06\",\n",
    "        \"July\": \"07\",\n",
    "        \"August\": \"08\",\n",
    "        \"September\": \"09\",\n",
    "        \"October\": \"10\",\n",
    "        \"November\": \"11\",\n",
    "        \"December\": \"12\"\n",
    "    }\n",
    "    # Get the month abbreviation from the match\n",
    "    month_abbrev = match.group(3)\n",
    "    # Use the abbreviation to look up the full month name\n",
    "    full_month = month_abbreviations.get(month_abbrev, month_abbrev)\n",
    "    return f\"{match.group(5)}-{full_month}-{match.group(1)}\"\n",
    "\n",
    "def parse_date(page_text): \n",
    "    # The top of the page is always:  \"Daily Weather Summary for Sunday 01 January 2023 \\n\".\n",
    "    pre_index = page_text.find('day') + 3 # we cant be sure that the pdf if correctly read 100% so this should be quite generic\n",
    "    post_index = page_text.find('Selected')\n",
    "    # Get the date between the two token variables and add to the df\n",
    "    date = re.sub(r'[^a-zA-Z0-9]', '', page_text[pre_index:post_index]) \n",
    "    formatted_date = re.sub(r'(\\d{1,2})(\\s*)([A-Za-z]+)(\\s*)(\\d{3,4})', transform_month, date) # make sure to format the date correctly for\n",
    "    midnight = formatted_date + \"T00:00\"\n",
    "    noon = formatted_date + \"T12:00\"\n",
    "    print(midnight)\n",
    "    return np.datetime64(midnight), np.datetime64(noon)\n",
    "\n",
    "def process_met_pdf(file_path):\n",
    "    dtype_dict, _ = create_dtype_dict(file_path)\n",
    "\n",
    "    # This is the text at the top of the page where the weather tables are. We use it to know which pages we want to read\n",
    "    search_string = 'Selected UK readings at (L) 0000 and (R) 1200 UTC'\n",
    "    pattern = re.compile(r'\\s*'.join(re.escape(word) for word in search_string.split())) # the whitespace can be read incorrectly so we allow for optional whitespace\n",
    "    # This is the columns without the date. When we need the date we append it with ['Date'] + columns\n",
    "    columns = ['Date', 'Station_no', 'Station_name', 'PRESS', 'WDIR', 'WSPD', 'CLOUD', 'TEMP', 'TDEW']\n",
    "    df_dtypes = {'Date': \"datetime64[s]\", 'Station_no': int, 'Station_name': str, 'PRESS': float, 'WDIR': str, 'WSPD': float, 'CLOUD': float, 'TEMP': float, 'TDEW': float}\n",
    "    #         '1200_PRESS', '1200_WDIR', '1200_WSPD', '1200_CLOUD', '1200_TEMP', '1200_TDEW']\n",
    "\n",
    "    with open(file_path, 'rb') as pdf_raw:\n",
    "        pdf = PyPDF2.PdfReader(pdf_raw)\n",
    "        print(pdf.numPages)\n",
    "\n",
    "        df = pd.DataFrame(dtype_dict)\n",
    "        i = 0\n",
    "        while i < pdf.numPages:\n",
    "            page_text = pdf.pages[i].extract_text()\n",
    "            if re.search(pattern, page_text):\n",
    "                table = camelot.read_pdf(file_path, pages=str(i + 1))\n",
    "\n",
    "                table_df = table[0].df\n",
    "                table_df = table_df.iloc[2:] # cut of the header of the table\n",
    "                \n",
    "                midnight_df = table_df.iloc[:,0:8]\n",
    "                noon_columns = table_df.columns[:2].union(table_df.columns[8:])\n",
    "                noon_df = table_df[noon_columns]\n",
    "\n",
    "                midnight_date, noon_date = parse_date(page_text)\n",
    "                \n",
    "                midnight_df.insert(0, \"Date\", midnight_date)\n",
    "                midnight_df = midnight_df.replace(\"-\", np.nan)\n",
    "                midnight_df.columns = columns\n",
    "                midnight_df = midnight_df.astype(df_dtypes)\n",
    "                \n",
    "                noon_df.insert(0, \"Date\", noon_date)\n",
    "                noon_df = noon_df.replace(\"-\", np.nan)\n",
    "                noon_df.columns = columns\n",
    "                noon_df = noon_df.astype(df_dtypes)\n",
    "                \n",
    "                df = pd.concat([df, midnight_df, noon_df], ignore_index=True)\n",
    "                i += 6\n",
    "            i += 1\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6625379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_exists(table_name, conn): \n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = c.fetchall()\n",
    "    tables = [table[0] for table in tables]\n",
    "    return table_name in tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be0dad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: READM\n"
     ]
    }
   ],
   "source": [
    "data_path=\"../data/landing/persistent/*\"\n",
    "# connect to the formatted zone database\n",
    "conn = sqlite3.connect('../data/formatted_zone/formatted_zone.db')\n",
    "for file in glob.glob(data_path): \n",
    "    table_name = file.split(\"\\\\\")[-1][:-4]\n",
    "    if table_exists(table_name, conn):\n",
    "        continue\n",
    "    print(f\"Processing: {table_name}\")\n",
    "    # only move .csv and .pdf files to a table\n",
    "    if file.split(\".\")[-1] == \"csv\":\n",
    "        dtype_dict, date_columns = create_dtype_dict(table_name)\n",
    "        df = pd.read_csv(file, dtype=dtype_dict, parse_dates=date_columns)\n",
    "        df.to_sql(table_name, con=conn, if_exists='fail', index=False) # IMPORTANT if you want to replace tables, change th if_exists to \"replace\"\n",
    "\n",
    "    if file.split(\".\")[-1] == \"pdf\": \n",
    "        # this will create a new table per pdf file\n",
    "        df = process_met_pdf(file)\n",
    "        df.to_sql(table_name, con=conn, if_exists='fail', index=False)\n",
    "\n",
    "# close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK THE TABLES ON THE DB\n",
    "conn = sqlite3.connect('../data/formatted_zone/formatted_zone.db')\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = c.fetchall()\n",
    "for table in tables: \n",
    "    table_name = table[0]\n",
    "    print(table_name)\n",
    "    dtype_dict, date_columns = create_dtype_dict(table_name)\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM \\\"{table_name}\\\";\", conn, parse_dates=date_columns)\n",
    "    print(df.describe())\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496dfcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT Metdata to correct datatypes. Only needed because JÃ³hannes forgot to when processing pdfs initially\n",
    "# df_dtypes = {'Date': \"datetime64[s]\", 'Station_no': int, 'Station_name': str, 'PRESS': float, 'WDIR': str, 'WSPD': float, 'CLOUD': float, 'TEMP': float, 'TDEW': float}\n",
    "# conn = sqlite3.connect('../data/formatted_zone/formatted_zone.db')\n",
    "# c = conn.cursor()\n",
    "# c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "# tables = c.fetchall()\n",
    "# for table in tables: \n",
    "#     table_name = table[0]\n",
    "#     if 'Metoffice' not in table_name: continue\n",
    "#     print(table_name)\n",
    "#     dtype_dict, date_columns = create_dtype_dict(table_name)\n",
    "#     df = pd.read_sql_query(f\"SELECT * FROM \\\"{table_name}\\\";\", conn, parse_dates=date_columns)\n",
    "#     df = df.astype(df_dtypes)\n",
    "#     df.to_sql(table_name, con=conn, if_exists='replace', index=False)\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "443a10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f1a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive analysis\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 500)\n",
    "conn = sqlite3.connect('../data/formatted_zone/formatted_zone.db')\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = c.fetchall()\n",
    "with open('../data/formatted_zone/descriptive_analysis.txt', mode='w') as f:\n",
    "    for table in tables: \n",
    "        table_name = table[0]\n",
    "        f.write(table_name+\"\\n\\n\")\n",
    "        dtype_dict, date_columns = create_dtype_dict(table_name)\n",
    "        df = pd.read_sql_query(f\"SELECT * FROM \\\"{table_name}\\\";\", conn, parse_dates=date_columns)\n",
    "        f.write(str(df.describe(include='all', datetime_is_numeric=True)))\n",
    "        f.write('\\n')\n",
    "        f.write(str(df.isna().sum()))\n",
    "        f.write('\\n')\n",
    "        df.hist(figsize=(10,6))\n",
    "        plt.savefig(f'../data/formatted_zone/img/{table_name}_profile.png')\n",
    "conn.close()\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.width')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
