{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e333ca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import camelot\n",
    "import PyPDF2\n",
    "import glob\n",
    "import re\n",
    "import sqlite3\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee194502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dtype_dict(filename): \n",
    "    if 'cleaned_merged_seasons' in filename: \n",
    "        return ({\n",
    "            'season_x': str,\n",
    "            'name': str,\n",
    "            'position': str,\n",
    "            'team_x': str,\n",
    "            'assists': int, \n",
    "            'bonus': int, \n",
    "            'bps': int, \n",
    "            'clean_sheets': int,\n",
    "            'creativity': float, \n",
    "            'element': int,\n",
    "            'fixture': int,\n",
    "            'goals_conceded': int, \n",
    "            'goals_scored': int, \n",
    "            'ict_index': float,\n",
    "            'influence': float, \n",
    "            'kickoff_time': str,\n",
    "            'minutes': int,\n",
    "            'opponent_team': int, \n",
    "            'opp_team_name': str,\n",
    "            'own_goals': int,\n",
    "            'penalties_missed': int, \n",
    "            'penalties_saved': int, \n",
    "            'red_cards': int, \n",
    "            'round': int, \n",
    "            'saves': int, \n",
    "            'selected': int, \n",
    "            'team_a_score': int, \n",
    "            'team_h_score': int,\n",
    "            'threat': int,\n",
    "            'total_points': int, \n",
    "            'transfers_balance': int, \n",
    "            'transfers_in': int, \n",
    "            'transfers_out': int, \n",
    "            'value': int, \n",
    "            'was_home': int, \n",
    "            'yellow_cards': int, \n",
    "            'GW': int\n",
    "        },\n",
    "        ['kickoff_time']\n",
    "        )\n",
    "    elif 'football-data' in filename: \n",
    "        return ({\n",
    "            \"Div\": str, # = League Division\n",
    "            \"Date\": str, # = Match Date (dd/mm/yy)\n",
    "            \"Time\": str, # = Time of match kick off\n",
    "            \"HomeTeam\": str, # = Home Team\n",
    "            \"AwayTeam\": str, # = Away Team\n",
    "            \"FTHG\": int, #  = Full Time Home Team Goals\n",
    "            \"FTAG\": int, # = Full Time Away Team Goals\n",
    "            \"FTR\": str, # Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "            \"HTHG\": int, # = Half Time Home Team Goals\n",
    "            \"HTAG\": int, # = Half Time Away Team Goals\n",
    "            \"HTR\": str,  # = Half Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "\n",
    "            \"Referee\": str, # = Match Referee\n",
    "            \"HS\": int, # = Home Team Shots\n",
    "            \"AS\": int, # = Away Team Shots\n",
    "            \"HST\": int, # = Home Team Shots on Target\n",
    "            \"AST\": int, # = Away Team Shots on Target\n",
    "            \"HF\": int, # = Home Team Fouls Committed\n",
    "            \"AF\": int, # = Away Team Fouls Committed\n",
    "            \"HC\": int, # = Home Team Corners\n",
    "            \"AC\": int, # = Away Team Corners\n",
    "            \"HY\": int, # = Home Team Yellow Cards\n",
    "            \"AY\": int, # = Away Team Yellow Cards\n",
    "            \"HR\": int, # = Home Team Red Cards\n",
    "            \"AR\": int, # = Away Team Red Cards\n",
    "\n",
    "            \"B365H\": float, # = Bet365 home win odds\n",
    "            \"B365D\": float, # = Bet365 draw odds\n",
    "            \"B365A\": float, # = Bet365 away win odds\n",
    "            \"BWH\": float, # = Bet&Win home win odds\n",
    "            \"BWD\": float, # = Bet&Win draw odds\n",
    "            \"BWA\": float, # = Bet&Win away win odds\n",
    "            \"IWH\": float, # = Interwetten home win odds\n",
    "            \"IWD\": float, # = Interwetten draw odds\n",
    "            \"IWA\": float, # = Interwetten away win odds\n",
    "            \"PSH\": float, # and PH = Pinnacle home win odds\n",
    "            \"PSD\": float, # and PD = Pinnacle draw odds\n",
    "            \"PSA\": float, # and PA = Pinnacle away win odds\n",
    "            \"WHH\": float, # = William Hill home win odds\n",
    "            \"WHD\": float, # = William Hill draw odds\n",
    "            \"WHA\": float, # = William Hill away win odds\n",
    "            \"VCH\": float, # = VC Bet home win odds\n",
    "            \"VCD\": float, # = VC Bet draw odds\n",
    "            \"VCA\": float, # = VC Bet away win odds\n",
    "            \n",
    "            \"MaxH\": float, # = Market maximum home win odds\n",
    "            \"MaxD\": float, # = Market maximum draw win odds\n",
    "            \"MaxA\": float, # = Market maximum away win odds\n",
    "            \"AvgH\": float, # = Market average home win odds\n",
    "            \"AvgD\": float, # = Market average draw win odds\n",
    "            \"AvgA\": float, # = Market average away win odds\n",
    "\n",
    "            \"B365>2.5\": float, # = Bet365 over 2.5 goals\n",
    "            \"B365<2.5\": float, # = Bet365 under 2.5 goals\n",
    "            \"P>2.5\": float, # = Pinnacle over 2.5 goals\n",
    "            \"P<2.5\": float, # = Pinnacle under 2.5 goals\n",
    "            \"Max>2.5\": float, # = Market maximum over 2.5 goals\n",
    "            \"Max<2.5\": float, # = Market maximum under 2.5 goals\n",
    "            \"Avg>2.5\": float, # = Market average over 2.5 goals\n",
    "            \"Avg<2.5\": float, # = Market average under 2.5 goals\n",
    "            \n",
    "            \"AHh\": float, # = Market size of handicap (home team) (since 2019/2020)\n",
    "            \"B365AHH\": float, # = Bet365 Asian handicap home team odds\n",
    "            \"B365AHA\": float, # = Bet365 Asian handicap away team odds\n",
    "            \"PAHH\": float, # = Pinnacle Asian handicap home team odds\n",
    "            \"PAHA\": float, # = Pinnacle Asian handicap away team odds\n",
    "            \"MaxAHH\": float, # = Market maximum Asian handicap home team odds\n",
    "            \"MaxAHA\": float, # = Market maximum Asian handicap away team odds\t\n",
    "            \"AvgAHH\": float, # = Market average Asian handicap home team odds\n",
    "            \"AvgAHA\": float, # = Market average Asian handicap away team odds\n",
    "\n",
    "            # Closing odds\n",
    "            \"B365CH\": float, # = Bet365 home win odds\n",
    "            \"B365CD\": float, # = Bet365 draw odds\n",
    "            \"B365CA\": float, # = Bet365 away win odds\n",
    "            \"BWCH\": float, # = Bet&Win home win odds\n",
    "            \"BWCD\": float, # = Bet&Win draw odds\n",
    "            \"BWCA\": float, # = Bet&Win away win odds\n",
    "            \"IWCH\": float, # = Interwetten home win odds\n",
    "            \"IWCD\": float, # = Interwetten draw odds\n",
    "            \"IWCA\": float, # = Interwetten away win odds\n",
    "            \"PSCH\": float, # and PH = Pinnacle home win odds\n",
    "            \"PSCD\": float, # and PD = Pinnacle draw odds\n",
    "            \"PSCA\": float, # and PA = Pinnacle away win odds\n",
    "            \"WHCH\": float, # = William Hill home win odds\n",
    "            \"WHCD\": float, # = William Hill draw odds\n",
    "            \"WHCA\": float, # = William Hill away win odds\n",
    "            \"VCCH\": float, # = VC Bet home win odds\n",
    "            \"VCCD\": float, # = VC Bet draw odds\n",
    "            \"VCCA\": float, # = VC Bet away win odds\n",
    "            \n",
    "            \"MaxCH\": float, # = Market maximum home win odds\n",
    "            \"MaxCD\": float, # = Market maximum draw win odds\n",
    "            \"MaxCA\": float, # = Market maximum away win odds\n",
    "            \"AvgCH\": float, # = Market average home win odds\n",
    "            \"AvgCD\": float, # = Market average draw win odds\n",
    "            \"AvgCA\": float, # = Market average away win odds\n",
    "\n",
    "            \"B365C>2.5\": float, # = Bet365 over 2.5 goals\n",
    "            \"B365C<2.5\": float, # = Bet365 under 2.5 goals\n",
    "            \"PC>2.5\": float, # = Pinnacle over 2.5 goals\n",
    "            \"PC<2.5\": float, # = Pinnacle under 2.5 goals\n",
    "            \"MaxC>2.5\": float, # = Market maximum over 2.5 goals\n",
    "            \"MaxC<2.5\": float, # = Market maximum under 2.5 goals\n",
    "            \"AvgC>2.5\": float, # = Market average over 2.5 goals\n",
    "            \"AvgC<2.5\": float, # = Market average under 2.5 goals\n",
    "            \n",
    "            \"AHCh\": float, # = Market size of handicap (home team) (since 2019/2020)\n",
    "            \"B365CAHH\": float, # = Bet365 Asian handicap home team odds\n",
    "            \"B365CAHA\": float, # = Bet365 Asian handicap away team odds\n",
    "            \"PCAHH\": float, # = Pinnacle Asian handicap home team odds\n",
    "            \"PCAHA\": float, # = Pinnacle Asian handicap away team odds\n",
    "            \"MaxCAHH\": float, # = Market maximum Asian handicap home team odds\n",
    "            \"MaxCAHA\": float, # = Market maximum Asian handicap away team odds\t\n",
    "            \"AvgCAHH\": float, # = Market average Asian handicap home team odds\n",
    "            \"AvgCAHA\": float, # = Market average Asian handicap away team odds\n",
    "        },\n",
    "        ['Date', 'Time']\n",
    "        )\n",
    "    elif 'master_team_list' in filename: \n",
    "        return ({\n",
    "            'season': str, \n",
    "            'team': int,\n",
    "            'team_name': str\n",
    "        },\n",
    "        []\n",
    "        )\n",
    "    elif 'Metoffice' in filename: \n",
    "        return ({\n",
    "            'Date': pd.Series([], dtype=\"datetime64[s]\"),\n",
    "            'Station_no': pd.Series([], dtype=int), \n",
    "            'Station_name': pd.Series([], dtype=str), \n",
    "            'PRESS': pd.Series([], dtype=float), \n",
    "            'WDIR': pd.Series([], dtype=str), \n",
    "            'WSPD': pd.Series([], dtype=float), \n",
    "            'CLOUD': pd.Series([], dtype=float), \n",
    "            'TEMP': pd.Series([], dtype=float)\n",
    "        },\n",
    "        ['Date']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b34a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_month(match):\n",
    "    month_abbreviations = {\n",
    "        \"January\": \"01\",\n",
    "        \"February\": \"02\",\n",
    "        \"March\": \"03\",\n",
    "        \"April\": \"04\",\n",
    "        \"May\": \"05\",\n",
    "        \"June\": \"06\",\n",
    "        \"July\": \"07\",\n",
    "        \"August\": \"08\",\n",
    "        \"September\": \"09\",\n",
    "        \"October\": \"10\",\n",
    "        \"November\": \"11\",\n",
    "        \"December\": \"12\"\n",
    "    }\n",
    "    # Get the month abbreviation from the match\n",
    "    month_abbrev = match.group(3)\n",
    "    # Use the abbreviation to look up the full month name\n",
    "    full_month = month_abbreviations.get(month_abbrev, month_abbrev)\n",
    "    return f\"{match.group(5)}-{full_month}-{match.group(1)}\"\n",
    "\n",
    "def parse_date(page_text): \n",
    "    # The top of the page is always:  \"Daily Weather Summary for Sunday 01 January 2023 \\n\".\n",
    "    pre_index = page_text.find('day') + 3 # we cant be sure that the pdf if correctly read 100% so this should be quite generic\n",
    "    post_index = page_text.find('Selected')\n",
    "    # Get the date between the two token variables and add to the df\n",
    "    date = re.sub(r'[^a-zA-Z0-9]', '', page_text[pre_index:post_index]) \n",
    "    formatted_date = re.sub(r'(\\d{1,2})(\\s*)([A-Za-z]+)(\\s*)(\\d{3,4})', transform_month, date) # make sure to format the date correctly for\n",
    "    midnight = formatted_date + \"T00:00\"\n",
    "    noon = formatted_date + \"T12:00\"\n",
    "    print(midnight)\n",
    "    return np.datetime64(midnight), np.datetime64(noon)\n",
    "\n",
    "def process_met_pdf(file_path):\n",
    "    dtype_dict, _ = create_dtype_dict(file_path)\n",
    "\n",
    "    # This is the text at the top of the page where the weather tables are. We use it to know which pages we want to read\n",
    "    search_string = 'Selected UK readings at (L) 0000 and (R) 1200 UTC'\n",
    "    pattern = re.compile(r'\\s*'.join(re.escape(word) for word in search_string.split())) # the whitespace can be read incorrectly so we allow for optional whitespace\n",
    "    # This is the columns without the date. When we need the date we append it with ['Date'] + columns\n",
    "    columns = ['Date', 'Station_no', 'Station_name', 'PRESS', 'WDIR', 'WSPD', 'CLOUD', 'TEMP', 'TDEW']\n",
    "    df_dtypes = {'Date': \"datetime64[s]\", 'Station_no': int, 'Station_name': str, 'PRESS': float, 'WDIR': str, 'WSPD': float, 'CLOUD': float, 'TEMP': float, 'TDEW': float}\n",
    "    #         '1200_PRESS', '1200_WDIR', '1200_WSPD', '1200_CLOUD', '1200_TEMP', '1200_TDEW']\n",
    "\n",
    "    with open(file_path, 'rb') as pdf_raw:\n",
    "        pdf = PyPDF2.PdfReader(pdf_raw)\n",
    "        print(pdf.numPages)\n",
    "\n",
    "        df = pd.DataFrame(dtype_dict)\n",
    "        i = 0\n",
    "        while i < pdf.numPages:\n",
    "            page_text = pdf.pages[i].extract_text()\n",
    "            if re.search(pattern, page_text):\n",
    "                table = camelot.read_pdf(file_path, pages=str(i + 1))\n",
    "\n",
    "                table_df = table[0].df\n",
    "                table_df = table_df.iloc[2:] # cut of the header of the table\n",
    "                \n",
    "                midnight_df = table_df.iloc[:,0:8]\n",
    "                noon_columns = table_df.columns[:2].union(table_df.columns[8:])\n",
    "                noon_df = table_df[noon_columns]\n",
    "\n",
    "                midnight_date, noon_date = parse_date(page_text)\n",
    "                \n",
    "                midnight_df.insert(0, \"Date\", midnight_date)\n",
    "                midnight_df = midnight_df.replace(\"-\", np.nan)\n",
    "                midnight_df.columns = columns\n",
    "                midnight_df = midnight_df.astype(df_dtypes)\n",
    "                \n",
    "                noon_df.insert(0, \"Date\", noon_date)\n",
    "                noon_df = noon_df.replace(\"-\", np.nan)\n",
    "                noon_df.columns = columns\n",
    "                noon_df = noon_df.astype(df_dtypes)\n",
    "                \n",
    "                df = pd.concat([df, midnight_df, noon_df], ignore_index=True)\n",
    "                i += 6\n",
    "            i += 1\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6625379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_exists(table_name, conn): \n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = c.fetchall()\n",
    "    tables = [table[0] for table in tables]\n",
    "    return table_name in tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0dad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../data/landing/persistent/*\"\n",
    "# connect to the formatted zone database\n",
    "conn = sqlite3.connect('../data/formatted_zone/formatted_zone.db')\n",
    "for file in glob.glob(data_path): \n",
    "    table_name = file.split(\"\\\\\")[-1][:-4]\n",
    "    if table_exists(table_name, conn):\n",
    "        continue\n",
    "    print(f\"Processing: {table_name}\")\n",
    "    # only move .csv and .pdf files to a table\n",
    "    if file.split(\".\")[-1] == \"csv\":\n",
    "        dtype_dict, date_columns = create_dtype_dict(table_name)\n",
    "        df = pd.read_csv(file, dtype=dtype_dict, parse_dates=date_columns)\n",
    "        df.to_sql(table_name, con=conn, if_exists='fail', index=False) # IMPORTANT if you want to replace tables, change th if_exists to \"replace\"\n",
    "\n",
    "    if file.split(\".\")[-1] == \"pdf\": \n",
    "        # this will create a new table per pdf file\n",
    "        df = process_met_pdf(file)\n",
    "        df.to_sql(table_name, con=conn, if_exists='fail', index=False)\n",
    "\n",
    "# close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK THE TABLES ON THE DB\n",
    "conn = sqlite3.connect('../data/formatted_zone/formatted_zone.db')\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = c.fetchall()\n",
    "for table in tables: \n",
    "    table_name = table[0]\n",
    "    print(table_name)\n",
    "    dtype_dict, date_columns = create_dtype_dict(table_name)\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM \\\"{table_name}\\\";\", conn, parse_dates=date_columns)\n",
    "    print(df.describe())\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496dfcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT Metdata to correct datatypes. Only needed because Jóhannes forgot to when processing pdfs initially\n",
    "# df_dtypes = {'Date': \"datetime64[s]\", 'Station_no': int, 'Station_name': str, 'PRESS': float, 'WDIR': str, 'WSPD': float, 'CLOUD': float, 'TEMP': float, 'TDEW': float}\n",
    "# conn = sqlite3.connect('../data/formatted_zone/formatted_zone.db')\n",
    "# c = conn.cursor()\n",
    "# c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "# tables = c.fetchall()\n",
    "# for table in tables: \n",
    "#     table_name = table[0]\n",
    "#     if 'Metoffice' not in table_name: continue\n",
    "#     print(table_name)\n",
    "#     dtype_dict, date_columns = create_dtype_dict(table_name)\n",
    "#     df = pd.read_sql_query(f\"SELECT * FROM \\\"{table_name}\\\";\", conn, parse_dates=date_columns)\n",
    "#     df = df.astype(df_dtypes)\n",
    "#     df.to_sql(table_name, con=conn, if_exists='replace', index=False)\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "443a10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f1a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive analysis\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "conn = sqlite3.connect('../data/formatted_zone/formatted_zone.db')\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = c.fetchall()\n",
    "with open('../data/formatted_zone/descriptive_analysis.txt', mode='w') as f:\n",
    "    for table in tables: \n",
    "        table_name = table[0]\n",
    "        f.write(table_name+\"\\n\\n\")\n",
    "        dtype_dict, date_columns = create_dtype_dict(table_name)\n",
    "        df = pd.read_sql_query(f\"SELECT * FROM \\\"{table_name}\\\";\", conn, parse_dates=date_columns)\n",
    "        f.write(str(df.describe(include='all', datetime_is_numeric=True)))\n",
    "        f.write(str(df.isna().sum()))\n",
    "        df.hist(figsize=(10,6))\n",
    "        plt.savefig(f'../data/formatted_zone/img/{table_name}_profile.png')\n",
    "conn.close()\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb42d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
