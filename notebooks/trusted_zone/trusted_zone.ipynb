{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb \n",
    "import math\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_zone_db = '../data/formatted_zone/formatted_zone.db'\n",
    "trusted_zone_db = '../data/trusted_zone/trusted_zone.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables(conn):\n",
    "    tables_lists = conn.sql(\"SHOW TABLES\").fetchall()\n",
    "    return [t[0] for t in tables_lists]\n",
    "\n",
    "def is_numeric(column): \n",
    "    try: \n",
    "        pd.to_numeric(column, errors='raise')\n",
    "        return True\n",
    "    except: \n",
    "        return False\n",
    "    \n",
    "def table_exists(table_name, conn):\n",
    "    return table_name in get_tables(conn)\n",
    "\n",
    "def get_table_df(table_name, conn):\n",
    "    return conn.sql(f\"SELECT * FROM \\\"{table_name}\\\";\").df()\n",
    "\n",
    "def drop_table(table_name, conn):\n",
    "    if table_exists(table_name, conn):\n",
    "        conn.sql(f\"DROP TABLE \\\"{table_name}\\\"\")\n",
    "    \n",
    "def create_table(table_name, df, conn, replace=True):\n",
    "    if replace & table_exists(table_name, conn): \n",
    "        drop_table(table_name, conn)\n",
    "    conn.sql(f\"CREATE TABLE \\\"{table_name}\\\" AS SELECT * FROM df\")\n",
    "\n",
    "def append_table(table_name, df, conn):\n",
    "    conn.sql(f\"INSERT INTO \\\"{table_name}\\\" SELECT * FROM df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the file with the last date, \n",
    "# ex: for filename=cleaned_merged_seasons would return cleaned_merged_seasons_2023-09-22.csv\n",
    "from datetime import datetime\n",
    "def get_last_table(table_names, fileformat=\"csv\"):\n",
    "    format_str = \"%Y-%m-%d\"  # Date format\n",
    "    most_recent_file = max(\n",
    "        table_names, \n",
    "        key=lambda f: datetime.strptime(f[-len(\"yyyy-MM-dd\"):], format_str)\n",
    "    )\n",
    "    return most_recent_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Metoffice_01_22_2023-09-22', 'Metoffice_01_23_2023-09-22', 'Metoffice_02_22_2023-09-22', 'Metoffice_02_23_2023-09-22', 'Metoffice_03_22_2023-09-22', 'Metoffice_03_23_2023-09-22', 'Metoffice_04_22_2023-09-22', 'Metoffice_04_23_2023-09-22', 'Metoffice_05_22_2023-09-22', 'Metoffice_05_23_2023-09-22', 'Metoffice_06_22_2023-09-22', 'Metoffice_06_23_2023-09-22', 'Metoffice_07_22_2023-09-22', 'Metoffice_07_23_2023-09-22', 'Metoffice_08_22_2023-09-22', 'Metoffice_08_23_2023-09-22', 'Metoffice_09_22_2023-09-22', 'Metoffice_10_22_2023-09-22', 'Metoffice_11_22_2023-09-22', 'Metoffice_12_22_2023-09-22', 'cleaned_merged_seasons_2023-09-22', 'football-data_2223_2023-09-22', 'master_team_list_2023-09-22', 'team_stadium_location_2023-10-23', 'team_stadium_location_2023-10-26', 'weather_station_locations_2023-10-23']\n"
     ]
    }
   ],
   "source": [
    "# get all the tables in the formatted zone\n",
    "conn = duckdb.connect(formatted_zone_db)\n",
    "formatted_zone_tables = get_tables(conn)\n",
    "print(formatted_zone_tables)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_zone_table = 'team_stadium_location'\n",
    "team_stadium_location_tables = filter(lambda x: x.startswith(trusted_zone_table), formatted_zone_tables)\n",
    "# the data from all seasons is all in one table so we only need to find the latest version of the table\n",
    "latest_table_name = get_last_table(team_stadium_location_tables)\n",
    "conn = duckdb.connect(formatted_zone_db)\n",
    "df = get_table_df(latest_table_name, conn)\n",
    "conn.close()\n",
    "# do some data quality checks\n",
    "assert df.isna().sum().sum() == 0\n",
    "assert df.LAT.dtype == np.float64\n",
    "assert df.LON.dtype == np.float64\n",
    "\n",
    "\n",
    "conn = duckdb.connect(trusted_zone_db)\n",
    "create_table(trusted_zone_table, df, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_zone_table = 'cleaned_merged_seasons'\n",
    "cleaned_merged_seasons_tables = filter(lambda x: x.startswith(trusted_zone_table), formatted_zone_tables)\n",
    "# the data from all seasons is all in one table so we only need to find the latest version of the table\n",
    "latest_table_name = get_last_table(cleaned_merged_seasons_tables)\n",
    "conn = duckdb.connect(formatted_zone_db)\n",
    "df = get_table_df(latest_table_name, conn)\n",
    "conn.close()\n",
    "# do some data quality checks\n",
    "conn = duckdb.connect(trusted_zone_db)\n",
    "stadium_df = get_table_df(\"team_stadium_location\", conn)\n",
    "conn.close()\n",
    "\n",
    "temp_set = set(df.team_x) - set(stadium_df.team_name)\n",
    "temp_set.discard(None)\n",
    "assert len(temp_set) == 0\n",
    "\n",
    "assert not is_numeric(df.season_x)\n",
    "assert not is_numeric(df.name)\n",
    "assert not is_numeric(df.position)\n",
    "assert not is_numeric(df.team_x)\n",
    "assert not is_numeric(df.opp_team_name)\n",
    "\n",
    "assert is_numeric(df.assists)\n",
    "assert is_numeric(df.bonus)\n",
    "assert is_numeric(df.bps)\n",
    "assert is_numeric(df.clean_sheets)\n",
    "assert is_numeric(df.creativity)\n",
    "assert is_numeric(df.element)\n",
    "assert is_numeric(df.fixture)\n",
    "assert is_numeric(df.goals_conceded)\n",
    "assert is_numeric(df.goals_scored)\n",
    "assert is_numeric(df.ict_index)\n",
    "assert is_numeric(df.influence)\n",
    "assert is_numeric(df.kickoff_time)\n",
    "assert is_numeric(df.minutes)\n",
    "assert is_numeric(df.opponent_team)\n",
    "assert is_numeric(df.own_goals)\n",
    "assert is_numeric(df.penalties_missed)\n",
    "assert is_numeric(df.penalties_saved)\n",
    "assert is_numeric(df.red_cards)\n",
    "assert is_numeric(df['round'])\n",
    "assert is_numeric(df.saves)\n",
    "assert is_numeric(df.selected)\n",
    "assert is_numeric(df.team_a_score)\n",
    "assert is_numeric(df.team_h_score)\n",
    "assert is_numeric(df.threat)\n",
    "assert is_numeric(df.total_points)\n",
    "assert is_numeric(df.transfers_balance)\n",
    "assert is_numeric(df.transfers_in)\n",
    "assert is_numeric(df.transfers_out)\n",
    "assert is_numeric(df.value)\n",
    "assert is_numeric(df.was_home)\n",
    "assert is_numeric(df.yellow_cards)\n",
    "assert is_numeric(df.GW)\n",
    "\n",
    "conn = duckdb.connect(trusted_zone_db)\n",
    "create_table(trusted_zone_table, df, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_zone_table = 'weather_station_locations'\n",
    "weather_station_locations_tables = filter(lambda x: x.startswith(trusted_zone_table), formatted_zone_tables)\n",
    "# the data from all seasons is all in one table so we only need to find the latest version of the table\n",
    "latest_table_name = get_last_table(weather_station_locations_tables)\n",
    "conn = duckdb.connect(formatted_zone_db)\n",
    "df = get_table_df(latest_table_name, conn)\n",
    "conn.close()\n",
    "# do some data quality checks\n",
    "assert df.isna().sum().sum() == 0\n",
    "assert is_numeric(df.LAT)\n",
    "assert is_numeric(df.LON)\n",
    "\n",
    "conn = duckdb.connect(trusted_zone_db)\n",
    "create_table(trusted_zone_table, df, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(lat1, lon1, lat2, lon2):\n",
    "    # Assuming the Britain can be approximated as a flat plane, calculate the distance using Pythagoras' theorem\n",
    "    lat_diff = lat2 - lat1\n",
    "    lon_diff = lon2 - lon1\n",
    "    distance = math.sqrt(lat_diff**2 + lon_diff**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "def wdir_to_deg(wdir): \n",
    "    wdir_dict = {\n",
    "        \"N\": 0,\n",
    "        \"E\": 90,\n",
    "        \"S\": 180,\n",
    "        \"W\": 270\n",
    "    }\n",
    "\n",
    "    for i, c in enumerate(wdir): \n",
    "        if i == 0: deg = wdir_dict[wdir[len(wdir) - 1 - i]]\n",
    "        else: \n",
    "            deg = (deg + wdir_dict[wdir[len(wdir) - 1 - i]]) / 2\n",
    "\n",
    "    return deg\n",
    "\n",
    "def deg_to_wdir(deg): \n",
    "    wind_directions = [\n",
    "        ('N', (345, 15)),\n",
    "        ('NNE', (15, 30)),\n",
    "        ('NE', (30, 60)),\n",
    "        ('ENE', (60, 75)),\n",
    "        ('E', (75, 105)),\n",
    "        ('ESE', (105, 120)),\n",
    "        ('SE', (120, 150)),\n",
    "        ('SSE', (150, 165)),\n",
    "        ('S', (165,195)),\n",
    "        ('SSW', (195,210)),\n",
    "        ('SW', (210,240)),\n",
    "        ('WSW', (240,255)),\n",
    "        ('W', (255,285)),\n",
    "        ('WNW', (285,300)),\n",
    "        ('NW', (300,330)),\n",
    "        ('NNW', (330,345))\n",
    "    ]\n",
    "    \n",
    "    # Loop through the wind direction abbreviations and degree ranges\n",
    "    for direction, (lower, upper) in wind_directions:\n",
    "        if lower <= deg < upper:\n",
    "            return direction\n",
    "\n",
    "    # If the input degrees are outside the defined ranges, return 'N' (North)\n",
    "    return 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_zone_table = 'Metoffice'\n",
    "metoffice_tables = list(filter(lambda x: x.startswith(trusted_zone_table), formatted_zone_tables))\n",
    "# group all tables for the same month\n",
    "unique_met_months = list(set([t[:-len(\"_yyyy-MM-dd\")] for t in metoffice_tables]))\n",
    "\n",
    "\n",
    "# trusted_conn = duckdb.connect(trusted_zone_db)\n",
    "# drop_table(trusted_zone_table, trusted_conn)\n",
    "df = None\n",
    "\n",
    "for month in unique_met_months: \n",
    "    month_tables = filter(lambda x: x.startswith(month), metoffice_tables)\n",
    "\n",
    "    # pick the newest table for the season\n",
    "    latest_table_name = get_last_table(month_tables)\n",
    "    \n",
    "    formated_conn = duckdb.connect(formatted_zone_db)\n",
    "    df = pd.concat([df, get_table_df(latest_table_name,formated_conn)])\n",
    "    formated_conn.close()\n",
    "\n",
    "\n",
    "# impute missing values\n",
    "\n",
    "conn = duckdb.connect(trusted_zone_db)\n",
    "loc_df = get_table_df('weather_station_locations', conn)\n",
    "conn.close()\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "imputed_df = df.__deepcopy__()\n",
    "\n",
    "for column in df.columns:\n",
    "    # iterate through the dataframe\n",
    "    for i, value in enumerate(df[column]):\n",
    "        if pd.isna(value):\n",
    "            station = df.loc[i, \"Station_name\"]\n",
    "            date = df.iloc[i].Date\n",
    "\n",
    "            # check if this station should be interpolated for this column\n",
    "            start_date = date - timedelta(days = 1)\n",
    "            end_date = date + timedelta(days = 1)\n",
    "            \n",
    "            prev_measure = np.nan\n",
    "            post_measure = np.nan\n",
    "            t = df.loc[(df.Station_name == station) & (df.Date == start_date)]\n",
    "            if len(t) > 0: prev_measure = t[column].iloc[0]\n",
    "\n",
    "            t = df.loc[(df.Station_name == station) & (df.Date == end_date)]\n",
    "            if len(t) > 0: post_measure = t[column].iloc[0]\n",
    "\n",
    "            if not np.isnan(prev_measure) and isinstance(prev_measure, (int, float)) and not np.isnan(post_measure) and isinstance(post_measure, (int, float)): \n",
    "                interpolated_value = np.mean([prev_measure, post_measure])\n",
    "            else: \n",
    "                # mean of nearby stations\n",
    "                lat = loc_df.loc[loc_df.SITE == station].LAT\n",
    "                lon = loc_df.loc[loc_df.SITE == station].LON\n",
    "                loc_df['Distance'] = loc_df.apply(lambda row: euclidean_distance(lat, lon, row['LAT'], row['LON']), axis=1)\n",
    "                # Sort the DataFrame by distance\n",
    "                loc_df = loc_df.sort_values(by='Distance')\n",
    "\n",
    "                # Select the top three closest stations\n",
    "                closest_stations = list(loc_df.head(4).SITE)\n",
    "                closest_df = df.loc[(df.Date == date) & df.Station_name.apply(lambda x: x in closest_stations)]\n",
    "\n",
    "                if column == 'WDIR': \n",
    "                    interpolated_value = deg_to_wdir(closest_df.loc[:,column].apply(wdir_to_deg).mean())\n",
    "                else: \n",
    "                    interpolated_value = closest_df.loc[:,column].mean()\n",
    "            \n",
    "            # print(i, interpolated_value, station, column, date)\n",
    "            imputed_df.loc[i, column] = interpolated_value\n",
    "\n",
    "assert not is_numeric(imputed_df.Station_name)\n",
    "assert not is_numeric(imputed_df.WDIR)\n",
    "\n",
    "assert is_numeric(imputed_df.Station_no)\n",
    "assert is_numeric(imputed_df.PRESS)\n",
    "assert is_numeric(imputed_df.WSPD)\n",
    "assert is_numeric(imputed_df.CLOUD)\n",
    "assert is_numeric(imputed_df.TEMP)\n",
    "assert is_numeric(imputed_df.TDEW)\n",
    "\n",
    "conn = duckdb.connect(trusted_zone_db)\n",
    "create_table(trusted_zone_table, imputed_df, conn)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_zone_table = 'football-data'\n",
    "football_data_tables = list(filter(lambda x: x.startswith(trusted_zone_table), formatted_zone_tables))\n",
    "# group all tables for the same season \n",
    "unique_seasons = list(set([t[:-len(\"_yyyy-MM-dd\")] for t in football_data_tables]))\n",
    "\n",
    "\n",
    "df = None\n",
    "for season in unique_seasons: \n",
    "    season_tables = filter(lambda x: x.startswith(season), football_data_tables)\n",
    "    # pick the newest table for the season\n",
    "    latest_table_name = get_last_table(season_tables)\n",
    "    \n",
    "    # retrieve the formatted zone df\n",
    "    formatted_conn = duckdb.connect(formatted_zone_db)\n",
    "    df = pd.concat([df, get_table_df(latest_table_name, formatted_conn)])\n",
    "    formatted_conn.close()\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "imputed_df = df.__deepcopy__()\n",
    "\n",
    "\n",
    "assert (df.FTR != df.apply(lambda row: \"D\" if row[\"FTHG\"] == row[\"FTAG\"] else \"H\" if row[\"FTHG\"] > row[\"FTAG\"] else \"A\", axis=1)).sum() == 0\n",
    "assert (df.HTR != df.apply(lambda row: \"D\" if row[\"HTHG\"] == row[\"HTAG\"] else \"H\" if row[\"HTHG\"] > row[\"HTAG\"] else \"A\", axis=1)).sum() == 0\n",
    "assert (df.HS < df.HST).sum() == 0\n",
    "assert (df.AS < df.AST).sum() == 0\n",
    "\n",
    "for column in df.columns[24:]:\n",
    "    backup_column = None\n",
    "    original_columns = None\n",
    "\n",
    "    if   column in [\"B365H\",\"BWH\",\"IWH\",\"PSH\",\"WHH\",\"VCH\"]: \n",
    "        backup_column = \"AvgH\" \n",
    "        original_columns = [\"B365H\",\"BWH\",\"IWH\",\"PSH\",\"WHH\",\"VCH\"]\n",
    "    elif column in [\"B365D\",\"BWD\",\"IWD\",\"PSD\",\"WHD\",\"VCD\"]: \n",
    "        backup_column = \"AvgD\" \n",
    "        original_columns = [\"B365D\",\"BWD\",\"IWD\",\"PSD\",\"WHD\",\"VCD\"]\n",
    "    elif column in [\"B365A\",\"BWA\",\"IWA\",\"PSA\",\"WHA\",\"VCA\"]: \n",
    "        backup_column = \"AvgA\" \n",
    "        original_columns = [\"B365A\",\"BWA\",\"IWA\",\"PSA\",\"WHA\",\"VCA\"]\n",
    "    elif column in [\"B365>2.5\",\"P>2.5\"]: \n",
    "        backup_column = \"Avg>2.5\" \n",
    "        original_columns = [\"B365>2.5\",\"P>2.5\"]\n",
    "    elif column in [\"B365<2.5\",\"P<2.5\"]: \n",
    "        backup_column = \"Avg<2.5\" \n",
    "        original_columns = [\"B365<2.5\",\"P<2.5\"]\n",
    "    elif column in [\"AHh\",\"B365AHH\",\"PAHH\"]: \n",
    "        backup_column = \"AvgAHH\" \n",
    "        original_columns = [\"AHh\",\"B365AHH\",\"PAHH\"]\n",
    "    elif column in [\"B365AHA\",\"PAHA\"]: \n",
    "        backup_column = \"AvgAHA\" \n",
    "        original_columns = [\"B365AHA\",\"PAHA\"]\n",
    "    elif column in [\"B365CH\",\"BWCH\",\"IWCH\",\"PSCH\",\"WHCH\",\"VCCH\"]: \n",
    "        backup_column = \"AvgCH\" \n",
    "        original_columns = [\"B365CH\",\"BWCH\",\"IWCH\",\"PSCH\",\"WHCH\",\"VCCH\"]\n",
    "    elif column in [\"B365CD\",\"BWCD\",\"IWCD\",\"PSCD\",\"WHCD\",\"VCCD\"]: \n",
    "        backup_column = \"AvgCD\" \n",
    "        original_columns = [\"B365CD\",\"BWCD\",\"IWCD\",\"PSCD\",\"WHCD\",\"VCCD\"]\n",
    "    elif column in [\"B365CA\",\"BWCA\",\"IWCA\",\"PSCA\",\"WHCA\",\"VCCA\"]: \n",
    "        backup_column = \"AvgCA\" \n",
    "        original_columns = [\"B365CA\",\"BWCA\",\"IWCA\",\"PSCA\",\"WHCA\",\"VCCA\"]\n",
    "    elif column in [\"B365C>2.5\",\"PC>2.5\"]: \n",
    "        backup_column = \"AvgC>2.5\" \n",
    "        original_columns = [\"B365C>2.5\",\"PC>2.5\"]\n",
    "    elif column in [\"B365C<2.5\",\"PC<2.5\"]: \n",
    "        backup_column = \"AvgC<2.5\" \n",
    "        original_columns = [\"B365C<2.5\",\"PC<2.5\"]\n",
    "    elif column in [\"AHCh\",\"B365CAHH\",\"PCAHH\"]: \n",
    "        backup_column = \"AvgCAHH\" \n",
    "        original_columns = [\"AHCh\",\"B365CAHH\",\"PCAHH\"]\n",
    "    elif column in [\"B365CAHA\",\"PCAHA\"]: \n",
    "        backup_column = \"AvgCAHA\" \n",
    "        original_columns = [\"B365CAHA\",\"PCAHA\"]\n",
    "\n",
    "    \n",
    "    if   column in [\"AvgH\", \"MaxH\"]:        original_columns = [\"B365H\",\"BWH\",\"IWH\",\"PSH\",\"WHH\",\"VCH\"]\n",
    "    elif column in [\"AvgD\", \"MaxD\"]:        original_columns = [\"B365D\",\"BWD\",\"IWD\",\"PSD\",\"WHD\",\"VCD\"]\n",
    "    elif column in [\"AvgA\", \"MaxA\"]:        original_columns = [\"B365A\",\"BWA\",\"IWA\",\"PSA\",\"WHA\",\"VCA\"]\n",
    "    elif column in [\"Avg>2.5\", \"Max>2.5\"]:  original_columns = [\"B365>2.5\",\"P>2.5\"]\n",
    "    elif column in [\"Avg<2.5\", \"Max<2.5\"]:  original_columns = [\"B365<2.5\",\"P<2.5\"]\n",
    "    elif column in [\"AvgAHH\", \"MaxAHH\"]:    original_columns = [\"AHh\",\"B365AHH\",\"PAHH\"]\n",
    "    elif column in [\"AvgAHA\", \"MaxAHA\"]:    original_columns = [\"B365AHA\",\"PAHA\"]\n",
    "    elif column in [\"AvgCH\", \"MaxCH\"]:      original_columns = [\"B365CH\",\"BWCH\",\"IWCH\",\"PSCH\",\"WHCH\",\"VCCH\"]\n",
    "    elif column in [\"AvgCD\", \"MaxCD\"]:      original_columns = [\"B365CD\",\"BWCD\",\"IWCD\",\"PSCD\",\"WHCD\",\"VCCD\"]\n",
    "    elif column in [\"AvgCA\", \"MaxCA\"]:      original_columns = [\"B365CA\",\"BWCA\",\"IWCA\",\"PSCA\",\"WHCA\",\"VCCA\"]\n",
    "    elif column in [\"AvgC>2.5\", \"MaxC>2.5\"]:original_columns = [\"B365C>2.5\",\"PC>2.5\"]\n",
    "    elif column in [\"AvgC<2.5\", \"MaxC<2.5\"]:original_columns = [\"B365C<2.5\",\"PC<2.5\"]\n",
    "    elif column in [\"AvgCAHH\", \"MaxCAHH\"]:  original_columns = [\"AHCh\",\"B365CAHH\",\"PCAHH\"]\n",
    "    elif column in [\"AvgCAHA\", \"MaxCAHA\"]:  original_columns = [\"B365CAHA\",\"PCAHA\"]\n",
    "\n",
    "    for i, value in enumerate(df[column]):\n",
    "        if pd.isna(value): \n",
    "            if backup_column is None: # Avg or Max column\n",
    "                if column.startswith(\"Avg\"): \n",
    "                    imputed_value = df.loc[i, original_columns].mean()\n",
    "                elif column.startswith(\"Max\"): \n",
    "                    imputed_value = df.loc[i, original_columns].max()\n",
    "            else: \n",
    "                if pd.isna(df.loc[i, backup_column]): \n",
    "                    imputed_value = df.loc[i, original_columns].mean()\n",
    "                else: \n",
    "                    imputed_value = df.loc[i, backup_column]\n",
    "            imputed_df.loc[i, column] = imputed_value\n",
    "\n",
    "\n",
    "trusted_conn = duckdb.connect(trusted_zone_db)\n",
    "create_table(trusted_zone_table, imputed_df, trusted_conn)\n",
    "trusted_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
